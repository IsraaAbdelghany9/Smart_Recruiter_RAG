{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7c4ad145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# from typing import List, Dict\n",
    "\n",
    "# from pydantic import BaseModel, Field\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# # from crewai import Agent, Task, Crew, LLM\n",
    "# # from crewai.tools import tool\n",
    "\n",
    "# # import agentops\n",
    "\n",
    "# # from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a33c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv(\"../src/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "afcc0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "# genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import fitz  # PyMuPDF\n",
    "# import docx\n",
    "\n",
    "# def extract_text_from_pdf(file_path):\n",
    "#     text = \"\"\n",
    "#     with fitz.open(file_path) as doc:\n",
    "#         for page in doc:\n",
    "#             text += page.get_text()\n",
    "#     return text\n",
    "\n",
    "# def extract_text_from_docx(file_path):\n",
    "#     doc = docx.Document(file_path)\n",
    "#     return \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "\n",
    "# def extract_text_from_txt(file_path):\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         return f.read()\n",
    "\n",
    "# def parse_cv(file_path):\n",
    "#     if file_path.endswith(\".pdf\"):\n",
    "#         return extract_text_from_pdf(file_path)\n",
    "#     elif file_path.endswith(\".docx\"):\n",
    "#         return extract_text_from_docx(file_path)\n",
    "#     elif file_path.endswith(\".txt\"):\n",
    "#         return extract_text_from_txt(file_path)\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# # Example: Parse all CVs in a folder\n",
    "# folder_path = \"../data/\"\n",
    "# parsed_cvs = []\n",
    "\n",
    "# for file_name in os.listdir(folder_path):\n",
    "#     file_path = os.path.join(folder_path, file_name)\n",
    "#     text = parse_cv(file_path)\n",
    "#     if text:\n",
    "#         parsed_cvs.append({\"filename\": file_name, \"text\": text})\n",
    "\n",
    "\n",
    "# # for cv in parsed_cvs:\n",
    "# #     print(f\"\\n--- {cv['filename']} ---\")\n",
    "# #     print(cv['text'])  # print only first 1000 characters to keep it short\n",
    "\n",
    "\n",
    "# def chunk_text(text, max_words=200):\n",
    "#     words = text.split()\n",
    "#     return [' '.join(words[i:i+max_words]) for i in range(0, len(words), max_words)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "# collection = client.get_or_create_collection(name=\"cv_chunks\")\n",
    "\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# for file in os.listdir(\"../data/\"):\n",
    "#     path = os.path.join(\"../data/\", file)\n",
    "#     text = parse_cv(path)\n",
    "#     if text:\n",
    "#         chunks = chunk_text(text)\n",
    "#         embeddings = model.encode(chunks).tolist()\n",
    "#         for i, chunk in enumerate(chunks):\n",
    "#             collection.add(\n",
    "#                 documents=[chunk],\n",
    "#                 embeddings=[embeddings[i]],\n",
    "#                 metadatas=[{\"filename\": file, \"chunk\": i}],\n",
    "#                 ids=[f\"{file}_{i}\"]\n",
    "#             )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b767280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_context_from_chromadb(question, collection, top_k=5):\n",
    "#     results = collection.query(query_texts=[question], n_results=top_k)\n",
    "#     return \"\\n\".join(results['documents'][0])\n",
    "\n",
    "# from crewai import Agent, Task\n",
    "# from pydantic import BaseModel, Field\n",
    "\n",
    "# class AnswerOutput(BaseModel):\n",
    "#     answer: str = Field(..., title=\"Answer to the user's question\")\n",
    "\n",
    "# research_Agent= Agent(\n",
    "#         role=\"Helpful Research Assistant\",\n",
    "#         goal=\"Answer user questions using provided context only.\",\n",
    "#         backstory=\"You are a helpful assistant that answers questions from CV/resume chunks.\",\n",
    "#         llm=basic_llm,\n",
    "#         verbose=True,\n",
    "#     )\n",
    "\n",
    "# research_Agent_task = Task(\n",
    "#     description=\"\\n\".join([\n",
    "#         f\"you are an expert in a {user_input} field to help beginner researchers in their writings .\",\n",
    "#         \"Provide a list of 3 to 5 trending topics or articals with a brief description for each.\",\n",
    "#         \"Focus on recent research interests supported by publication trends.\",\n",
    "#         \"Output in JSON format with 'topics' as list of objects {name, description}.\"\n",
    "#     ]),\n",
    "#     expected_output=\"JSON object with list of trending topics and descriptions.\",\n",
    "#     output_json=TrendingTopicsOutput,\n",
    "#     output_file=os.path.join(output_dir, \"step_1_trending_topics.json\"),\n",
    "#     agent=trending_topics_agent,\n",
    "# )\n",
    "\n",
    "# def build_answer_task(user_question, collection, output_dir, llm):\n",
    "#     context = get_context_from_chromadb(user_question, collection)\n",
    "#     agent = build_answer_agent(llm)\n",
    "\n",
    "#     return Task(\n",
    "#         description=\"\\n\".join([\n",
    "#             f\"Context:\\n{context}\",\n",
    "#             f\"Question: {user_question}\",\n",
    "#             \"Answer the question strictly based on the given context.\",\n",
    "#             \"Give a clear and concise answer.\"\n",
    "#         ]),\n",
    "#         expected_output=\"A short and accurate answer.\",\n",
    "#         output_json=AnswerOutput,\n",
    "#         output_file=os.path.join(output_dir, \"qa_answer.json\"),\n",
    "#         agent=agent,\n",
    "#     )\n",
    "\n",
    "\n",
    "# question = \"What programming languages does the candidate know?\"\n",
    "# task = build_answer_task(question, collection, output_dir=\"./outputs\", llm=basic_llm)\n",
    "# result = task.execute()\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3098f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0db7a2cd",
   "metadata": {},
   "source": [
    "## `01` Import Lib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4d254aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb176c",
   "metadata": {},
   "source": [
    "## `02` Directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dab4bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"../data/\"\n",
    "output_folder = \"../cvs_md_outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e861b",
   "metadata": {},
   "source": [
    "## `03` Model Config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5dab9109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../src/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "197e0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Gemini\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1084df",
   "metadata": {},
   "source": [
    "## `04` Extract text from a PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "44de08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    return \"\\n\".join(page.extract_text() for page in reader.pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dacfaf",
   "metadata": {},
   "source": [
    "## `05` Convert to markdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "166471a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_markdown(text):\n",
    "    prompt = \"\\n\".join([\n",
    "        \"You are a smart recruiter and CV expert.\",\n",
    "\n",
    "        \"Your task is to convert the following CV (extracted as raw PDF text) into clean, structured **Markdown** format using proper headings and bullet points.\",\n",
    "\n",
    "        \"Make the Markdown professional, readable, and consistently formatted.\",\n",
    "\n",
    "        \"Use the following structure **only if the information is present**.if not specified do not add it. Do NOT guess or add anything that's not in the text.\",\n",
    "\n",
    "        \"Add logic to group and classify content based on context and keywords.\",\n",
    "\n",
    "        \"Pay special attention to education and trainings:\\n\"\n",
    "        \"- Include ALL formal degrees and full-time academic programs (e.g., Bachelor's, ITI) under '## Education' Do not add ITI to Internships.\\n\"\n",
    "        \"- Do NOT mistakenly place formal education in '## Internships & Trainings'.\\n\"\n",
    "        \"- Short-term workshops, technical training, and certifications belong under '## Internships & Trainings'.\",\n",
    "\n",
    "        \"Use this Markdown structure:\",\n",
    "\n",
    "        \"# Full Name\\n\"\n",
    "        \"Job Title (e.g., AI & ML Engineer)\\n\",\n",
    "\n",
    "        \"## Contact Information\\n\"\n",
    "        \"* Email: ...\\n\"\n",
    "        \"* LinkedIn: ...\\n\"\n",
    "        \"* GitHub: ...\\n\"\n",
    "        \"* Kaggle: ...\\n\"\n",
    "        \"* Phone: ...\\n\"\n",
    "        \"* Address: ...\\n\"\n",
    "        \"* Birthdate: ...\\n\"\n",
    "        \"* Marital Status: ...\\n\",\n",
    "\n",
    "        \"## Profile\\n\"\n",
    "        \"A short summary paragraph of key strengths, technical areas, and goals.\\n\",\n",
    "\n",
    "        \"## Education\\n\"\n",
    "        \"* Degree – University – Date range\\n\"\n",
    "        \"* GPA, Rank, or Awards if available\\n\"\n",
    "        \"* Include ITI and all full-time formal education programs\\n\",\n",
    "\n",
    "        \"## Internships & Trainings\\n\"\n",
    "        \"* Program or Course – Institution – Date\\n\"\n",
    "        \"* Short description (1–2 lines) of practical work or skills learned\\n\"\n",
    "        \"* Include technical trainings, certifications, workshops, and hands-on practice\\n\",\n",
    "\n",
    "        \"## Projects\\n\"\n",
    "        \"* **Project Title:** Description, tools used, purpose, and outcomes\\n\"\n",
    "        \"* If a link is needed but missing, write [link needed]\\n\",\n",
    "\n",
    "        \"## Professional Experience\\n\"\n",
    "        \"* Job Title – Company – Date range\\n\"\n",
    "        \"* List responsibilities and technologies used\\n\",\n",
    "\n",
    "        \"## Technical Skills\\n\"\n",
    "        \"* **Programming Languages:** C++, Python, etc.\\n\"\n",
    "        \"* **Software & Tools:** Git, LabView, MATLAB, ROS, etc.\\n\"\n",
    "        \"* **Libraries & Frameworks:** TensorFlow, PyTorch, OpenCV, etc.\\n\"\n",
    "        \"* **Domain Expertise:** Control Systems, Robotics, CNC, SolidWorks, etc.\\n\"\n",
    "        \"* **Operating Systems:** Linux, Windows, etc.\\n\"\n",
    "        \"* **Databases:** MySQL, MongoDB, etc.\\n\",\n",
    "\n",
    "        \"## Personal Skills\\n\"\n",
    "        \"* Soft skills, mindset, leadership, communication, etc.\\n\",\n",
    "\n",
    "        \"## Languages\\n\"\n",
    "        \"* Language: Proficiency (e.g., English: B2)\\n\",\n",
    "\n",
    "        \"## Courses\\n\"\n",
    "        \"* Course Title – Platform – Date\\n\",\n",
    "\n",
    "        \"## Publications (if any)\\n\"\n",
    "        \"* Title – Journal/Conference – Year\\n\",\n",
    "\n",
    "        \"## Awards (if any)\\n\"\n",
    "        \"* Award Name – Granting Body – Year or Description\\n\",\n",
    "\n",
    "        \"## Activities (if any)\\n\"\n",
    "        \"* Role or Activity – Organization – Date\\n\",\n",
    "        \"* Description of involvement or achievements\\n\",\n",
    "\n",
    "        \"## Volunteering (if any)\\n\"\n",
    "        \"* Role – Organization – Duration\\n\"\n",
    "        \"* Description of contributions\\n\",\n",
    "\n",
    "        \"### Skill Grouping Intuition:\\n\"\n",
    "        \"- If the skill reflects what the person *uses* (e.g., software, tools), put it under **Skills**.\\n\"\n",
    "        \"- If the skill reflects *how the person behaves or works* (e.g., problem-solving, leadership), put it under **Personal Skills**.\\n\"\n",
    "        \"- If unsure, ask: 'Is it a technical tool or a personal trait?'\\n\",\n",
    "\n",
    "        \"**Clean-up Rules:**\\n\"\n",
    "        \"- Remove broken lines, random symbols, page numbers, and noise from PDF\\n\"\n",
    "        \"- Keep spacing and indentation consistent\\n\"\n",
    "        \"- Never invent or hallucinate content\\n\",\n",
    "\n",
    "        \"Now convert the following CV into structured Markdown:\\n\\n\" + text\n",
    "    ])\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ababc728",
   "metadata": {},
   "source": [
    "## `06` Processing Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166857f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Alaa-Hussien-CV.pdf...\n",
      "Processing Adham Assy - Resume - AI & ML Engineer.pdf...\n"
     ]
    }
   ],
   "source": [
    "# Process each PDF\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_folder, filename)\n",
    "        print(f\"Processing {filename}...\")\n",
    "\n",
    "        text = extract_text(pdf_path)\n",
    "        markdown = convert_to_markdown(text)\n",
    "\n",
    "        md_filename = os.path.splitext(filename)[0] + \".md\"\n",
    "        md_path = os.path.join(output_folder, md_filename)\n",
    "\n",
    "        with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(markdown)\n",
    "\n",
    "print(\"✅ All CVs converted to Markdown.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8c05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83457b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f32b88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
