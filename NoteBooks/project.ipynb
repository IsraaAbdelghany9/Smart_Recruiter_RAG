{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ad145",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ChatGoogle' from 'crewai.llms' (/home/israa/Desktop/Smart_Recruiter_RAG/.venv/lib/python3.10/site-packages/crewai/llms/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent, Task, Crew, LLM\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tool\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcrewai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogle  \u001b[38;5;66;03m# FIXED here\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# import agentops\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# from tavily import TavilyClient\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ChatGoogle' from 'crewai.llms' (/home/israa/Desktop/Smart_Recruiter_RAG/.venv/lib/python3.10/site-packages/crewai/llms/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai.tools import tool\n",
    "\n",
    "# import agentops\n",
    "\n",
    "# from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a33c645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  # Load from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afcc0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac00eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'LLM' has no attribute 'ChatGoogle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m basic_llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatGoogle\u001b[49m(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini/gemini-1.5-flash\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m      4\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mGEMINI_API_KEY\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'LLM' has no attribute 'ChatGoogle'"
     ]
    }
   ],
   "source": [
    "basic_llm = ChatGoogle(\n",
    "    model=\"gemini/gemini-1.5-flash\",\n",
    "    temperature=0.2,\n",
    "    api_key=GEMINI_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cdc21cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LLM' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mbasic_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList top 3 programming languages for data science.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LLM' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "response = basic_llm.invoke(\"List top 3 programming languages for data science.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc16fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import docx\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "\n",
    "def extract_text_from_txt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def parse_cv(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        return extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith(\".txt\"):\n",
    "        return extract_text_from_txt(file_path)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example: Parse all CVs in a folder\n",
    "folder_path = \"../data/\"\n",
    "parsed_cvs = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    text = parse_cv(file_path)\n",
    "    if text:\n",
    "        parsed_cvs.append({\"filename\": file_name, \"text\": text})\n",
    "\n",
    "\n",
    "# for cv in parsed_cvs:\n",
    "#     print(f\"\\n--- {cv['filename']} ---\")\n",
    "#     print(cv['text'])  # print only first 1000 characters to keep it short\n",
    "\n",
    "\n",
    "def chunk_text(text, max_words=200):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+max_words]) for i in range(0, len(words), max_words)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mClient(Settings(chroma_db_impl\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduckdb+parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./chroma_db\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      6\u001b[0m collection \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_or_create_collection(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "client = chromadb.Client(Settings(chroma_db_impl=\"duckdb+parquet\", persist_directory=\"./chroma_db\"))\n",
    "collection = client.get_or_create_collection(name=\"cv_chunks\")\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "for file in os.listdir(\"../data/\"):\n",
    "    path = os.path.join(\"../data/\", file)\n",
    "    text = parse_cv(path)\n",
    "    if text:\n",
    "        chunks = chunk_text(text)\n",
    "        embeddings = model.encode(chunks).tolist()\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            collection.add(\n",
    "                documents=[chunk],\n",
    "                embeddings=[embeddings[i]],\n",
    "                metadatas=[{\"filename\": file, \"chunk\": i}],\n",
    "                ids=[f\"{file}_{i}\"]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
